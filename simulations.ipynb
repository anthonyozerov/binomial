{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, norm, t\n",
    "from methods import birge, random_effects_hksj, binomial_method, binomial_adapt, binomial_sigmacdf, random_effects_dl, sign_rank, flip_interval, random_effects_mle, vniim\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# use tex\n",
    "plt.rc(\"text\", usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | label: table-n-nb\n",
    "\n",
    "p = 0.5\n",
    "coverages_mu = []\n",
    "target_coverage = 0.6827\n",
    "tail_alpha = (1 - target_coverage) / 2\n",
    "\n",
    "\n",
    "\n",
    "# ns = [3, 10, 31, 100, 316, 1000]\n",
    "# ns = np.logspace(0.5, 3, 6).astype(int)\n",
    "#ns = np.logspace(0.5, 2, 4).astype(int)\n",
    "ns = [3, 10, 31]\n",
    "tail_alphas = {}\n",
    "target_coverages = {}\n",
    "rows = []\n",
    "for n in ns:\n",
    "    ks = np.arange(0, n + 1)\n",
    "    cdf = binom.cdf(ks, n, p)\n",
    "    tail_alpha_achieved = cdf[np.argmax(np.array(cdf) >= tail_alpha) - 1]\n",
    "    tail_alphas[n] = tail_alpha_achieved\n",
    "    target_coverages[n] = 1 - 2 * tail_alpha_achieved\n",
    "    z_score = norm.ppf(1 - tail_alpha_achieved)\n",
    "    new_row = {\n",
    "        \"n\": n,\n",
    "        \"target_coverage\": np.round(target_coverages[n], 3),\n",
    "        \"tail_alpha\": np.round(tail_alpha_achieved, 3),\n",
    "        \"z_score\": np.round(z_score, 3),\n",
    "    }\n",
    "    rows.append(new_row)\n",
    "\n",
    "table = pd.DataFrame(rows)\n",
    "# set n column as index\n",
    "table.set_index(\"n\", inplace=True)\n",
    "# print as markdown table\n",
    "print(table.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mus = np.logspace(-3, 3, 13)\n",
    "mus = np.logspace(-2, 2, 9)\n",
    "\n",
    "models = ['nonoise', 're_hksj', 're_dl', 'birge', 'signrank', 're_mle', 'pdg', 'vniim'] #'flip']#, 'binomial_adapt', 'binomial_sigmacdf']\n",
    "\n",
    "settings = [\n",
    "    \"random_effects\",\n",
    "    \"birge\",\n",
    "    \"random_effects_outliers\",\n",
    "    # \"adversarial\",\n",
    "    # \"random_effects_corr\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for i in range(len(settings)):\n",
    "    setting = settings[i]\n",
    "    results[setting] = {}\n",
    "    total = len(ns) * len(mus)\n",
    "    for n, mu in tqdm(itertools.product(ns, mus), total=total):\n",
    "        results[setting][(n, mu)] = {}\n",
    "\n",
    "        tail_alpha = tail_alphas[n]\n",
    "        target_coverage = 1 - 2 * tail_alpha\n",
    "        z_alpha = norm.ppf(1 - tail_alpha)\n",
    "        t_alpha = t.ppf(1 - tail_alpha, n - 1)\n",
    "\n",
    "        ks = np.arange(0, n + 1)\n",
    "        cdf = binom.cdf(ks, n, p)\n",
    "\n",
    "        coverages = {k: [] for k in models}\n",
    "        coverages_ba = []\n",
    "        coverages_bs = []\n",
    "        lengths = {k : [] for k in models}\n",
    "        midpoints = {k : [] for k in models}\n",
    "\n",
    "        for j in range(1000):\n",
    "            # noise_magnitudes = np.clip(np.random.normal(1, 0.25, n), 0.1, None)\n",
    "            noise_magnitudes = np.random.exponential(1, n)\n",
    "            if setting == \"random_effects\":\n",
    "                systematic_errors = np.random.normal(0, mu, n)\n",
    "                random_errors = np.random.normal(0, noise_magnitudes, n)\n",
    "                values = systematic_errors + random_errors\n",
    "            elif setting == \"birge\":\n",
    "                random_errors = np.random.normal(0, noise_magnitudes, n)\n",
    "                values = random_errors * mu\n",
    "            elif setting == \"random_effects_outliers\":\n",
    "                systematic_errors = np.random.standard_cauchy(n) * mu\n",
    "                random_errors = np.random.normal(0, noise_magnitudes, n)\n",
    "                values = systematic_errors + random_errors\n",
    "            elif setting == \"adversarial\":\n",
    "                random_errors = np.random.normal(0, noise_magnitudes, n)\n",
    "                values = mu + random_errors\n",
    "            elif setting == \"random_effects_corr\":\n",
    "                if n > 100:\n",
    "                    continue\n",
    "                Sigma = mu**2 * (0.8 * np.eye(n) + 0.2 * np.ones((n, n)))\n",
    "                rng = np.random.default_rng()\n",
    "                systematic_errors = rng.multivariate_normal(\n",
    "                    np.zeros(n), Sigma, method=\"cholesky\"\n",
    "                )\n",
    "                # systematic_errors = np.random.multivariate_normal(np.zeros(n), Sigma) TOO SLOW\n",
    "                # noise_magnitudes = np.random.exponential(1, n)\n",
    "                random_errors = np.random.normal(0, noise_magnitudes, n)\n",
    "                values = systematic_errors + random_errors\n",
    "            else:\n",
    "                raise ValueError(\"setting not recognized\")\n",
    "\n",
    "            values_sort = np.sort(values)\n",
    "\n",
    "            lower_nonoise, _ = binomial_method(\n",
    "                values_sort, p=p, target=tail_alpha, which=\"lower\", cdf=cdf\n",
    "            )\n",
    "            upper_nonoise, _ = binomial_method(\n",
    "                values_sort, p=p, target=tail_alpha, which=\"upper\", cdf=cdf\n",
    "            )\n",
    "\n",
    "            interval_nonoise = [lower_nonoise, upper_nonoise]\n",
    "            covers_nonoise = interval_nonoise[0] < 0 and interval_nonoise[1] > 0\n",
    "\n",
    "            interval_signrank, _ = sign_rank(values, coverage=target_coverage)\n",
    "\n",
    "\n",
    "            # interval_binomial_adapt, coverage_ba = binomial_adapt(values, noise_magnitudes, p, 0.6827, cdf, which='random')\n",
    "            # coverages_ba.append(coverage_ba)\n",
    "            # interval_binomial_sigmacdf, cvg = binomial_sigmacdf(values, noise_magnitudes, p, 0.6827)\n",
    "            # coverages_bs.append(cvg)\n",
    "\n",
    "            # calculate using random-effects model\n",
    "            interval_re_hksj, muhat, sigma, _ = random_effects_hksj(\n",
    "                values, noise_magnitudes, talpha=t_alpha\n",
    "            )\n",
    "\n",
    "            interval_re_dl, muhat, sigma, _ = random_effects_dl(\n",
    "                values, noise_magnitudes, zalpha=z_alpha\n",
    "            )\n",
    "\n",
    "            interval_re_mle, muhat, sigma, _ = random_effects_mle(\n",
    "                values, noise_magnitudes, zalpha=z_alpha\n",
    "            )\n",
    "\n",
    "            interval_birge, muhat, sigma, _ = birge(\n",
    "                values, noise_magnitudes, zalpha=z_alpha\n",
    "            )\n",
    "\n",
    "            interval_pdg, muhat, sigma, _ = birge(\n",
    "                values, noise_magnitudes, zalpha=z_alpha, pdg=True\n",
    "            )\n",
    "\n",
    "            interval_vniim, muhat = vniim(\n",
    "                values, noise_magnitudes, zalpha=z_alpha\n",
    "            )\n",
    "\n",
    "            # interval_flip, _ = flip_interval(values, coverage=target_coverage, mode='median', boot=False)\n",
    "\n",
    "            intervals = {\n",
    "                \"nonoise\": interval_nonoise,\n",
    "                \"re_hksj\": interval_re_hksj,\n",
    "                \"re_dl\": interval_re_dl,\n",
    "                \"re_mle\": interval_re_mle,\n",
    "                \"birge\": interval_birge,\n",
    "                \"signrank\": interval_signrank,\n",
    "                \"pdg\": interval_pdg,\n",
    "                \"vniim\": interval_vniim,\n",
    "                # \"flip\": interval_flip,\n",
    "                # \"binomial_adapt\": interval_binomial_adapt,\n",
    "                # \"binomial_sigmacdf\": interval_binomial_sigmacdf\n",
    "            }\n",
    "\n",
    "            for k, v in intervals.items():\n",
    "                coverages[k].append(v[0] < 0 and v[1] > 0)\n",
    "                lengths[k].append(v[1] - v[0])\n",
    "                midpoints[k].append((v[0] + v[1]) / 2)\n",
    "\n",
    "        result_dict = results[setting][(n, mu)]\n",
    "        # result_dict['t_coverage_binomial_adapt'] = np.mean(coverages_ba)\n",
    "        # result_dict['t_coverage_binomial_sigmacdf'] = np.mean(coverages_bs)\n",
    "\n",
    "        for k in models:\n",
    "            lengths[k] = np.array(lengths[k])\n",
    "\n",
    "            result_dict[\"coverage_\" + k] = np.mean(coverages[k])\n",
    "            result_dict[\"length_median_\" + k] = np.median(lengths[k])\n",
    "            result_dict[\"length_mean_\" + k] = np.mean(lengths[k])\n",
    "            result_dict[\"midpoint_median\" + k] = np.median(np.abs(midpoints[k]))\n",
    "            result_dict[\"midpoint_mean_\" + k] = np.mean(np.abs(midpoints[k]))\n",
    "            result_dict[\"length_median_relbinomial_\" + k] = np.median(lengths[k]/lengths[\"nonoise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['random_effects'][(3, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"nonoise\": \"red\",\n",
    "    \"re_hksj\": \"blue\",\n",
    "    \"re_dl\": \"grey\",\n",
    "    \"re_mle\": \"purple\",\n",
    "    \"birge\": \"green\",\n",
    "    \"signrank\": \"orange\",\n",
    "    \"pdg\": \"black\",\n",
    "    \"vniim\": \"yellow\"\n",
    "    # \"flip\": \"brown\",\n",
    "    # \"binomial_adapt\": \"green\",\n",
    "    # \"binomial_sigmacdf\": \"green\"\n",
    "    }\n",
    "friendly_labels = {\n",
    "    \"nonoise\": \"Binomial\",\n",
    "    \"re_hksj\": \"HKSJ\",\n",
    "    # \"re_dl\": \"DL\",\n",
    "    \"re_mle\": \"MLE\",\n",
    "    \"birge\": \"Birge Ratio\",\n",
    "    # \"signrank\": \"Sign Rank\",\n",
    "    \"pdg\": \"PDG\",\n",
    "    \"vniim\": \"VNIIM\",\n",
    "    # \"binomial_adapt\": \"Binomial Adapt (BA)\"\n",
    "    # 'binomial_sigmacdf': 'Binomial SigmaCDF (BS)'\n",
    "}\n",
    "methods = friendly_labels.keys()\n",
    "setting_labels = {\n",
    "    \"random_effects\": \"Random Effects\",\n",
    "    \"birge\": \"Birge\",\n",
    "    \"random_effects_outliers\": \"Random Effects with Cauchy\",\n",
    "    \"adversarial\": \"Offset\",\n",
    "    \"random_effects_corr\": \"Correlated Random Effects\",\n",
    "}\n",
    "print(target_coverages)\n",
    "for setting in settings:\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(4, 6), sharex=True)\n",
    "    axs[0].axhline(0, color=\"black\", lw=1, ls=\"--\")\n",
    "    for method in methods:\n",
    "        # if method == 'birge':\n",
    "        #     continue\n",
    "        print(method)\n",
    "        for i, n in enumerate(ns):\n",
    "            if results[setting][(n, mus[0])] == {}:\n",
    "                continue\n",
    "            alpha = (i + 1) / len(ns)\n",
    "            target_coverage = target_coverages[n]\n",
    "            if method == 'binomial_adapt':\n",
    "                target_coverage = np.array([results[setting][(n, mu)]['t_coverage_binomial_adapt'] for mu in mus])\n",
    "            if method == 'binomial_sigmacdf':\n",
    "                target_coverage = np.array([results[setting][(n, mu)]['t_coverage_binomial_sigmacdf'] for mu in mus])\n",
    "            data = [results[setting][(n, mu)][f\"coverage_{method}\"] for mu in mus]\n",
    "            data = np.array(data) - target_coverage\n",
    "            if i == len(ns) - 1:\n",
    "                label = friendly_labels[method]\n",
    "            else:\n",
    "                label = None\n",
    "            axs[0].plot(mus, data, color=colors[method], label=label, alpha=alpha)\n",
    "            # data = np.array([results[setting][(n, mu)][f\"length_median_{method}\"] for mu in mus])\n",
    "            # data_bin = np.array([results[setting][(n, mu)][f\"length_median_nonoise\"] for mu in mus])\n",
    "            # axs[1].plot(mus, data/data_bin, color=colors[method], label=label, alpha=alpha)\n",
    "            data = np.array([results[setting][(n, mu)][f\"length_median_relbinomial_{method}\"] for mu in mus])\n",
    "            axs[1].plot(mus, data, color=colors[method], label=label, alpha=alpha)\n",
    "            # data = np.array([results[setting][(n, mu)][f\"midpoint_{method}\"] for mu in mus])\n",
    "            # data_bin = np.array([results[setting][(n, mu)][f\"midpoint_nonoise\"] for mu in mus])\n",
    "            # axs[2].plot(mus, data/data_bin, color=colors[method], label=label, alpha=alpha)\n",
    "            # axs[1].plot(mus, data, color=colors[method], label=label, alpha=alpha)\n",
    "    # add top and right ticks\n",
    "    for ax in axs:\n",
    "        ax.yaxis.set_ticks_position(\"both\")\n",
    "        ax.xaxis.set_ticks_position(\"both\")\n",
    "        # ax.tick_params(direction='in')\n",
    "        ax.tick_params(which=\"both\", direction=\"in\")\n",
    "        ax.set_xscale(\"log\")\n",
    "    axs[1].set_xlabel(r\"$\\tau$: size of systematic error relative to noise\")\n",
    "    # axs[0].set_ylim(-0.13, 0.075)\n",
    "\n",
    "    # log y scale on right axis\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    # axs[2].set_yscale(\"log\")\n",
    "    # axs[1].set_ylim(0, None)\n",
    "\n",
    "    # add legend with colors and corresponding labels\n",
    "    # plt.legend(frameon=False)\n",
    "\n",
    "    axs[0].set_ylabel(\"Coverage probability $-$ target coverage\")\n",
    "    axs[1].set_ylabel(\"Median interval width relative to Binomial\")\n",
    "    # axs[2].set_ylabel(r\"Median distance of midpoint from $\\theta$\")\n",
    "    plt.suptitle(f\"{setting_labels[setting]}\")\n",
    "    # plt.savefig(f\"figs/performance_{setting}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figs/performance_{setting}_exp.png', bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import binomial_adapt\n",
    "ys = np.arange(0, 15, 1) * 0.1\n",
    "n = len(ys)\n",
    "sigmas = np.ones(len(ys))\n",
    "\n",
    "probs = binomial_adapt(ys, sigmas, p=0.5)\n",
    "\n",
    "# first element in each row where the cumulative sum is greater than 0.6827\n",
    "idx_row = np.argmax(probs >= 0.6827, axis=1)\n",
    "\n",
    "idx_col = n - np.argmax(probs[::-1,:] >= 0.6827, axis=0) - 1\n",
    "\n",
    "# array elements which correspond to both an element of idx_row and idx_col\n",
    "selector_row = np.array([idx_row, np.arange(n)]).T\n",
    "selector_col = np.array([np.arange(n), idx_col]).T\n",
    "\n",
    "selected_row = np.zeros((n, n), dtype=bool)\n",
    "selected_col = np.zeros((n, n), dtype=bool)\n",
    "\n",
    "selected_row[np.arange(n), idx_row] = True\n",
    "selected_col[idx_col, np.arange(n)] = True\n",
    "plt.imshow((selected_row.astype(int) + selected_col.astype(int)) * (probs>0.6827).astype(int))\n",
    "plt.ylabel('Index of lower bound')\n",
    "plt.xlabel('Index of upper bound')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_good = selected_row & selected_col & (probs>0.6827)\n",
    "# indices of trues\n",
    "intervals_idx = np.array(interval_good.nonzero()).T\n",
    "intervals = ys[intervals_idx]\n",
    "intervals\n",
    "interval_lengths = intervals[:,1] - intervals[:,0]\n",
    "interval_lengths\n",
    "interval_probs = probs[intervals_idx[:,0], intervals_idx[:,1]]\n",
    "interval_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_l = np.abs((ys[:,np.newaxis] - intervals[:,0]))/sigmas[:,np.newaxis]\n",
    "errors_u = np.abs((ys[:,np.newaxis] - intervals[:,1]))/sigmas[:,np.newaxis]\n",
    "within = (ys[:, np.newaxis] >= intervals[:,0]) & (ys[:, np.newaxis] <= intervals[:,1])\n",
    "dists = np.minimum(errors_l, errors_u) * (~within)\n",
    "total_dist = np.sum(dists, axis=0)\n",
    "total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interval_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(selected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(selected_row & selected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(probs[selected_row & selected_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = (selected_row | selected_col) & (probs >= 0.6827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected[:30, 70:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[idx_row, np.arange(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Rmath4\n",
    "from tqdm import tqdm\n",
    "conf_level = 0.6827\n",
    "alpha = 1-conf_level\n",
    "covers = []\n",
    "for i in tqdm(range(8000000)):\n",
    "    y = np.random.normal(5,2,5)\n",
    "    n = len(y)\n",
    "    w = np.add.outer(y, y)/2\n",
    "    w = np.sort(w[np.tril_indices(w.shape[0], 0)])\n",
    "    qu = int(Rmath4.qsignrank(alpha/2, n, 0, 0))\n",
    "    if qu == 0:\n",
    "        qu = 1\n",
    "    ql = int(n*(n+1) / 2 - qu)\n",
    "    achieved_alpha = 2*Rmath4.psignrank(qu-1, n, 0, 0)\n",
    "    # print(achieved, len(w), qu)\n",
    "    # lower = w[ql+1-1]\n",
    "    # upper = w[qu-1]\n",
    "    lower = w[ql+1-1]\n",
    "    upper = w[qu-1]\n",
    "    # print(lower, upper)\n",
    "    covers.append(lower < 5 and upper > 5)\n",
    "print(np.mean(covers), 1-achieved_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rmath4.qsignrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.tril(w) != 0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
