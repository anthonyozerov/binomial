{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# use tex\n",
    "plt.rc(\"text\", usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_df = pd.read_csv('data/c.csv', comment='#')\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_df = pd.read_csv('data/rho.csv', comment='#')\n",
    "rho_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_df = pd.read_csv('data/au.csv', comment='#')\n",
    "au_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'rho': rho_df,\n",
    "    'c': c_df,\n",
    "    'au': au_df,\n",
    "}\n",
    "truths = {\n",
    "    'rho': 5.513,\n",
    "    'c': 299792.458,\n",
    "    'au': 149597870700,\n",
    "}\n",
    "yscales = {\n",
    "    'rho': 'symlog',\n",
    "    'c': 'symlog',\n",
    "    'au': 'symlog',\n",
    "}\n",
    "linthresh = {\n",
    "    'rho': 0.01,\n",
    "    'c': 0.1,\n",
    "    'au': 1,\n",
    "}\n",
    "\n",
    "nice_names = {\n",
    "    'c': 'Speed of light',\n",
    "    'rho': 'Density of Earth',\n",
    "    'au': 'Astronomical Unit',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "xlabels = {\n",
    "    'rho': r'Difference from true value $[\\mathrm{g/cm^3}]$',\n",
    "    'c': r'Difference from true value $[\\mathrm{km/s}]$',\n",
    "    'au': r'Difference from true value $[\\mathrm{km}]$',\n",
    "}\n",
    "historical_keys = ['rho', 'c', 'au']\n",
    "for i, name in enumerate(historical_keys):\n",
    "    ax = axs[i]\n",
    "\n",
    "    values = datasets[name].value - truths[name]\n",
    "    if name == 'au':\n",
    "        values = values / 1000\n",
    "    dates = datasets[name].year\n",
    "\n",
    "    ax.plot(values, dates, '.', color='black')\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "    # reverse y axis\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    if yscales[name] == 'symlog':\n",
    "        print(name)\n",
    "        ax.set_xscale('symlog', linthresh=linthresh[name])\n",
    "        # skip every other tick\n",
    "        n_ticklabels = len(ax.xaxis.get_ticklabels())\n",
    "        for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "            if n % 2 != 0 and label.get_text() != '$\\\\mathdefault{0}$':\n",
    "                label.set_visible(False)\n",
    "        ax.tick_params(axis='both', which='both', direction='in', top=True, right=True)\n",
    "    ax.set_xlabel(xlabels[name])\n",
    "    ax.set_ylabel('Year')\n",
    "    ax.set_ylim(2000, 1650)\n",
    "    ax.set_title(nice_names[name])\n",
    "    # make top x limit and bottom x limit equal\n",
    "    xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    ax.set_xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/historical.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get error on ratio calculations\n",
    "def clarke_ratio(A, a, B, b, C=100, c=0):\n",
    "    # if A:B is the ratio, we want x where A:B = C:x\n",
    "    value = (B / A) * C\n",
    "    uncertainty = np.sqrt((B*C*a/A)**2 + (C*b)**2 + (B*c)**2)/A\n",
    "    return value, uncertainty\n",
    "def clarke_quotient(A, a, B, b):\n",
    "    # get the ratio B:A and its error\n",
    "    value = B/A\n",
    "    uncertainity = np.sqrt((B*a/A)**2+b**2)/A\n",
    "    return value, uncertainity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_df = pd.read_csv('data/clarke/H-O-mass.csv', comment='#')\n",
    "ho_df['uncertainty'] = ho_df['proberr'] / 0.6745\n",
    "agcl_df = pd.read_csv('data/clarke/Ag-Cl-mass.csv', comment='#')\n",
    "agcl_df['uncertainty'] = agcl_df['proberr'] / 0.6745\n",
    "agi_df = pd.read_csv('data/clarke/Ag-I-mass.csv', comment='#')\n",
    "agi_df['uncertainty'] = agi_df['proberr'] / 0.6745\n",
    "agbr_df = pd.read_csv('data/clarke/Ag-Br-mass.csv', comment='#')\n",
    "agbr_df['uncertainty'] = agbr_df['proberr'] / 0.6745\n",
    "no_df = pd.read_csv('data/clarke/N-mass.csv', comment='#')\n",
    "no_df['uncertainty'] = no_df['proberr'] / 0.6745\n",
    "co_df = pd.read_csv('data/clarke/C-mass.csv', comment='#')\n",
    "co_df['uncertainty'] = co_df['proberr'] / 0.6745\n",
    "\n",
    "datasets['ho'] = ho_df\n",
    "datasets['agcl'] = agcl_df\n",
    "datasets['agi'] = agi_df\n",
    "datasets['agbr'] = agbr_df\n",
    "datasets['no'] = no_df\n",
    "datasets['co'] = co_df\n",
    "\n",
    "truths['agcl'] = clarke_ratio(107.8682, 0.0002, 35.453, 0.004, 100, 0)\n",
    "truths['agbr'] = clarke_ratio(107.8682, 0.0002, 79.904, 0.003, 100, 0)\n",
    "truths['agi'] = clarke_ratio(107.8682, 0.0002, 126.90447, 0.00003, 100, 0)\n",
    "truths['ho'] = clarke_quotient(1.0080, 0.0002, 15.9995, 0.0005)\n",
    "truths['no'] = clarke_ratio(15.9995, 0.0005, 14.007, 0.001, 16, 0)\n",
    "truths['co'] = clarke_ratio(15.9995, 0.0005, 12.011, 0.002, 16, 0)\n",
    "\n",
    "nice_names['ho'] = 'Oxygen to Hydrogen mass ratio'\n",
    "nice_names['agcl'] = 'Silver to Chlorine mass ratio'\n",
    "nice_names['agi'] = 'Silver to Iodine mass ratio'\n",
    "nice_names['agbr'] = 'Silver to Bromine mass ratio'\n",
    "nice_names['no'] = 'Nitrogen mass (O=16)'\n",
    "nice_names['co'] = 'Carbon mass (O=16)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(8, 5))\n",
    "from methods import birge, random_effects_hksj, binomial_method\n",
    "\n",
    "plot_est = False\n",
    "chemistry_keys = ['ho', 'agcl', 'agi', 'agbr', 'no', 'co']\n",
    "\n",
    "for i, name in enumerate(chemistry_keys):\n",
    "    ax = axs.flatten()[i]\n",
    "    # values = np.array(datasets[name].value - truths[name])\n",
    "    truth = truths[name][0]\n",
    "    err = truths[name][1]\n",
    "    ax.axvspan(truth-err, truth+err, color='black', alpha=0.3)\n",
    "\n",
    "    values = np.array(datasets[name].value)\n",
    "    errs = np.array(datasets[name].uncertainty)\n",
    "    # sort by decreasing error\n",
    "    sort_idx = np.argsort(errs)[::-1]\n",
    "    values = values[sort_idx]\n",
    "    errs = errs[sort_idx]\n",
    "    \n",
    "    ax.errorbar(values, np.arange(len(values)), xerr=errs, fmt='.', markersize=2, linewidth=1, color='black')\n",
    "    ax.invert_yaxis()\n",
    "    # xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    # ax.set_xlim(-xlim, xlim)\n",
    "    if plot_est:\n",
    "        interval_birge, _, _, _ = birge(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_birge[0], color='red', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_birge[1], color='red', linestyle='--', linewidth=1)\n",
    "        interval_re, _, _, _ = random_effects_hksj(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_re[0], color='blue', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_re[1], color='blue', linestyle='--', linewidth=1)\n",
    "        binomial_lower, _ = binomial_method(values, p=0.5, target=0.15865, which='lower')\n",
    "        ax.axvline(binomial_lower, color='green', linestyle='--', linewidth=1)\n",
    "        binomial_upper, _ = binomial_method(values, p=0.5, target=0.15865, which='upper')\n",
    "        ax.axvline(binomial_upper, color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_title(nice_names[name])\n",
    "\n",
    "    # ax.axvline(truth, color='black', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth-err, color='grey', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth+err, color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # ax.set_xlabel(xlabels[name])\n",
    "    # remove y ticks\n",
    "    ax.set_yticks([])\n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    xmin = ax.get_xlim()[0]\n",
    "    xmax = ax.get_xlim()[1]\n",
    "    ax.set_xlim(min(xmin, truth-err), max(xmax, truth+err))\n",
    "    # add top ticks\n",
    "    ax.tick_params(axis='x', top=True)\n",
    "    # make ticks point inwards\n",
    "    ax.tick_params(direction='in')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/chemical.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['lambda-lifetime'] = pd.read_csv('data/pdg1970/lambda-lifetime.csv', comment='#')\n",
    "datasets['sigma+-lifetime'] = pd.read_csv('data/pdg1970/sigma+-lifetime.csv', comment='#')\n",
    "datasets['pion-mass-diff'] = pd.read_csv('data/pdg1970/pion-mass-diff.csv', comment='#')\n",
    "datasets['charged-kaon-lifetime'] = pd.read_csv('data/pdg1970/charged-kaon-lifetime.csv', comment='#')\n",
    "datasets['charged-pion-lifetime'] = pd.read_csv('data/pdg1970/charged-pion-lifetime.csv', comment='#')\n",
    "datasets['eta-mass'] = pd.read_csv('data/pdg1970/eta-mass.csv', comment='#')\n",
    "\n",
    "truths['lambda-lifetime'] = (2.617, 0.010)\n",
    "truths['sigma+-lifetime'] = (0.8018, 0.0026)\n",
    "truths['pion-mass-diff'] = (4.5936, 0.0005)\n",
    "truths['charged-kaon-lifetime'] = (1.2380, 0.0020)\n",
    "truths['charged-pion-lifetime'] = (26.033, 0.005)\n",
    "truths['eta-mass'] = (547.862, 0.017)\n",
    "\n",
    "nice_names['lambda-lifetime'] = r'$\\Lambda$ mean lifetime $\\mathrm{[10^{-10}s]}$'\n",
    "nice_names['sigma+-lifetime'] = r'$\\Sigma^+$ mean lifetime $\\mathrm{[10^{-10}s]}$'\n",
    "nice_names['pion-mass-diff'] = r'$m_{\\pi^\\pm}-m_{\\pi^0}$ $\\mathrm{[MeV]}$'\n",
    "nice_names['charged-kaon-lifetime'] = r'$K^\\pm$ mean lifetime $\\mathrm{[10^{-8}s]}$'\n",
    "nice_names['charged-pion-lifetime'] = r'$\\pi^\\pm$ mean lifetime $\\mathrm{[10^{-9}s]}$'\n",
    "nice_names['eta-mass'] = r'$\\eta$ mass $\\mathrm{[MeV]}$'\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(8, 5))\n",
    "from methods import birge, random_effects_hksj, binomial_method\n",
    "\n",
    "plot_est = False\n",
    "particle_keys = ['lambda-lifetime', 'sigma+-lifetime', 'pion-mass-diff', 'charged-kaon-lifetime', 'charged-pion-lifetime', 'eta-mass']\n",
    "\n",
    "for i, name in enumerate(particle_keys):\n",
    "    ax = axs.flatten()[i]\n",
    "    # values = np.array(datasets[name].value - truths[name])\n",
    "    truth = truths[name][0]\n",
    "    err = truths[name][1]\n",
    "    ax.axvspan(truth-err, truth+err, color='black', alpha=0.3)\n",
    "\n",
    "    values = np.array(datasets[name].value)\n",
    "    errs = np.array(datasets[name].uncertainty)\n",
    "    # sort by decreasing error\n",
    "    sort_idx = np.argsort(datasets[name].year)\n",
    "    values = values[sort_idx]\n",
    "    errs = errs[sort_idx]\n",
    "    \n",
    "    ax.errorbar(values, np.arange(len(values)), xerr=errs, fmt='.', markersize=2, linewidth=1, color='black')\n",
    "    ax.invert_yaxis()\n",
    "    # xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    # ax.set_xlim(-xlim, xlim)\n",
    "    if plot_est:\n",
    "        interval_birge, _, _, _ = birge(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_birge[0], color='red', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_birge[1], color='red', linestyle='--', linewidth=1)\n",
    "        interval_re, _, _, _ = random_effects_hksj(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_re[0], color='blue', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_re[1], color='blue', linestyle='--', linewidth=1)\n",
    "        binomial_lower, _ = binomial_method(values, p=0.5, target=0.15865, which='lower')\n",
    "        ax.axvline(binomial_lower, color='green', linestyle='--', linewidth=1)\n",
    "        binomial_upper, _ = binomial_method(values, p=0.5, target=0.15865, which='upper')\n",
    "        ax.axvline(binomial_upper, color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_title(nice_names[name])\n",
    "\n",
    "    # ax.axvline(truth, color='black', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth-err, color='grey', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth+err, color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # ax.set_xlabel(xlabels[name])\n",
    "    # remove y ticks\n",
    "    ax.set_yticks([])\n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    xmin = ax.get_xlim()[0]\n",
    "    xmax = ax.get_xlim()[1]\n",
    "    ax.set_xlim(min(xmin, truth-err), max(xmax, truth+err))\n",
    "    # add top ticks\n",
    "    ax.tick_params(axis='x', top=True)\n",
    "    # make ticks point inwards\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "# remove unused axes\n",
    "for ax in axs.flatten()[len(particle_keys):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/particles.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "from methods import sign_rank_test\n",
    "\n",
    "names = list(datasets.keys())\n",
    "\n",
    "results = {}\n",
    "\n",
    "def fmt_result(result):\n",
    "    # result is a list\n",
    "    minmax = [min(result), max(result)]\n",
    "    result_fmt = [f'{x:.2g}' for x in minmax]\n",
    "    # get unique values (preserving order)\n",
    "    result_fmt = pd.unique(np.array(result_fmt))\n",
    "    if len(result_fmt) == 1:\n",
    "        return result_fmt[0]\n",
    "    else:\n",
    "        return f'[{\", \".join(result_fmt)}]'\n",
    "\n",
    "for n in names:\n",
    "    results[n] = {}\n",
    "    results[n]['count'] = len(datasets[n])\n",
    "\n",
    "    truth_vals = []\n",
    "    if hasattr(truths[n], '__iter__'):\n",
    "        truth_vals.append(truths[n][0]-truths[n][1])\n",
    "        truth_vals.append(truths[n][0]+truths[n][1])\n",
    "        truth_vals.append(truths[n][0])\n",
    "    else:\n",
    "        truth_vals.append(truths[n])\n",
    "    \n",
    "    results[n]['num_over'] = fmt_result([np.sum(datasets[n].value > t) for t in truth_vals])\n",
    "    results[n]['prop_over'] = fmt_result([np.sum(datasets[n].value > t) / len(datasets[n]) for t in truth_vals])\n",
    "\n",
    "    # binomial test\n",
    "    results[n]['binom_p_value'] = fmt_result([binomtest(np.sum(datasets[n].value > t), len(datasets[n]), p=0.5, alternative='two-sided').pvalue for t in truth_vals])\n",
    "\n",
    "    results[n]['sign_rank_p_value'] = fmt_result([sign_rank_test(datasets[n].value, t) for t in truth_vals])\n",
    "\n",
    "# put all the results in a pandas dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index = [nice_names[n] for n in names]\n",
    "\n",
    "print(results_df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import birge, random_effects_mle\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "results = {}\n",
    "def fmt_result(r):\n",
    "    if r == -np.inf:\n",
    "        return r'$\\approx-\\infty$'\n",
    "    else:\n",
    "        return r'{:.3g}'.format(r)\n",
    "category_map = {k: 'chemistry' for k in chemistry_keys}\n",
    "category_map.update({k: 'particle' for k in particle_keys})\n",
    "category_map.update({k: 'historical' for k in historical_keys})\n",
    "\n",
    "key_order = []\n",
    "\n",
    "for n in names:\n",
    "    values = datasets[n].value\n",
    "    sigmas = datasets[n].uncertainty\n",
    "    has_sigma = ~np.isnan(sigmas)\n",
    "    values = values[has_sigma]\n",
    "    sigmas = sigmas[has_sigma]\n",
    "    if len(values) < 2:\n",
    "        continue\n",
    "    key_order.append(n)\n",
    "    truth = truths[n][0] if hasattr(truths[n], '__iter__') else truths[n]\n",
    "    # scaler = truth\n",
    "    # values = values/scaler\n",
    "    # sigmas = sigmas/scaler\n",
    "    # truth = truth/scaler\n",
    "    results[n] = {}\n",
    "\n",
    "    _, muhat_birge, _, chat = birge(values, sigmas, coverage=0.6827, truth=truth)\n",
    "    # brs.append(chat)\n",
    "    # mean_sigma = np.mean(sigmas)\n",
    "    # muhat_re, _, tau = random_effects_dl_base(values, sigmas)\n",
    "    # taus.append(np.mean(tau/sigmas))\n",
    "    _, muhat_re, _, tau = random_effects_mle(values, sigmas, coverage=0.6827, truth=truth)\n",
    "    # taus.append(np.mean(tau/sigmas))\n",
    "    # I2s.append(I2(values, sigmas))\n",
    "\n",
    "    # # generate values with same sigmas but no unaccounted for errors.\n",
    "    # # to be used as a control when analyzing the distribution of chat and tau\n",
    "    # values_control = np.random.normal(loc=0, scale=sigmas)\n",
    "    # _, _, _, chat_cont = birge(values_control, sigmas, coverage=0.6827)\n",
    "    # brs_cont.append(chat_cont)\n",
    "    # _, _, _, tau_cont = random_effects_mle(values_control, sigmas, coverage=0.6827)\n",
    "    # taus_cont.append(np.mean(tau_cont/sigmas))\n",
    "    # I2s_cont.append(I2(values_control, sigmas))\n",
    "\n",
    "    # # errscale_ps.append(errscale_test(values, sigmas))\n",
    "    # # errscale_ps_cont.append(errscale_test(values_control, sigmas))\n",
    "\n",
    "    results[n]['name'] = nice_names[n]\n",
    "    results[n]['count'] = len(values)\n",
    "    # print(norm.pdf(values, loc=muhat_birge, scale=sigmas*chat))\n",
    "    results[n]['birge_loglike'] = np.sum(np.log(norm.pdf(values, loc=muhat_birge, scale=sigmas*chat)))\n",
    "    results[n]['re_loglike'] = np.sum(np.log(norm.pdf(values, loc=muhat_re, scale=np.sqrt(sigmas**2+tau**2))))\n",
    "    results[n]['fe_loglike'] = np.sum(np.log(norm.pdf(values, loc=muhat_birge, scale=sigmas)))\n",
    "\n",
    "    category = category_map[n]\n",
    "    if category not in results:\n",
    "        # dict with default value of zero\n",
    "        results[category] = defaultdict(int)\n",
    "    results[category]['count'] += len(values)\n",
    "    for r in ['birge_loglike', 're_loglike', 'fe_loglike']:\n",
    "        results[category][r] += results[n][r]\n",
    "    if 'total' not in results:\n",
    "        results['total'] = defaultdict(int)\n",
    "    results['total']['count'] += len(values)\n",
    "    for r in ['birge_loglike', 're_loglike', 'fe_loglike']:\n",
    "        results['total'][r] += results[n][r]\n",
    "\n",
    "for res in results.values():\n",
    "    for r in ['birge_loglike', 're_loglike', 'fe_loglike']:\n",
    "        res[r] = fmt_result(res[r])\n",
    "\n",
    "results['total']['name'] = 'Total'\n",
    "results['historical']['name'] = 'Total (historical)'\n",
    "results['chemistry']['name'] = 'Total (chemistry)'\n",
    "results['particle']['name'] = 'Total (particle)'\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "# results_df.index = [r['name'] for r in results.values()]\n",
    "# sort to be: chemistry, particle, total chemistry, total particle, total\n",
    "row_order = key_order + ['historical','chemistry', 'particle', 'total']\n",
    "results_df = results_df.loc[row_order]\n",
    "\n",
    "print(results_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
