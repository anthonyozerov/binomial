{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# use tex\n",
    "plt.rc(\"text\", usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_df = pd.read_csv('data/c.csv', comment='#')\n",
    "c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_df = pd.read_csv('data/rho.csv', comment='#')\n",
    "rho_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_df = pd.read_csv('data/au.csv', comment='#')\n",
    "au_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'rho': rho_df,\n",
    "    'c': c_df,\n",
    "    'au': au_df,\n",
    "}\n",
    "truths = {\n",
    "    'rho': 5.513,\n",
    "    'c': 299792.458,\n",
    "    'au': 149597870700,\n",
    "}\n",
    "yscales = {\n",
    "    'rho': 'symlog',\n",
    "    'c': 'symlog',\n",
    "    'au': 'symlog',\n",
    "}\n",
    "linthresh = {\n",
    "    'rho': 0.01,\n",
    "    'c': 0.1,\n",
    "    'au': 1,\n",
    "}\n",
    "\n",
    "nice_names = {\n",
    "    'c': 'Speed of light',\n",
    "    'rho': 'Density of Earth',\n",
    "    'au': 'Astronomical Unit',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5), sharey=True, gridspec_kw={'wspace': 0.05})\n",
    "xlabels = {\n",
    "    'rho': r'Difference from true value $[\\mathrm{g/cm^3}]$',\n",
    "    'c': r'Difference from true value $[\\mathrm{km/s}]$',\n",
    "    'au': r'Difference from true value $[\\mathrm{km}]$',\n",
    "}\n",
    "historical_keys = ['rho', 'c', 'au']\n",
    "for i, name in enumerate(historical_keys):\n",
    "    ax = axs[i]\n",
    "\n",
    "    values = datasets[name].value - truths[name]\n",
    "    if name == 'au':\n",
    "        values = values / 1000\n",
    "    dates = datasets[name].year\n",
    "\n",
    "    ax.plot(values, dates, '.', color='black')\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "    # reverse y axis\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    if yscales[name] == 'symlog':\n",
    "        print(name)\n",
    "        ax.set_xscale('symlog', linthresh=linthresh[name])\n",
    "        # skip every other tick\n",
    "        n_ticklabels = len(ax.xaxis.get_ticklabels())\n",
    "        for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "            if n % 2 != 0 and label.get_text() != '$\\\\mathdefault{0}$':\n",
    "                label.set_visible(False)\n",
    "        ax.tick_params(axis='both', which='both', direction='in', top=True, right=True)\n",
    "    ax.set_xlabel(xlabels[name])\n",
    "    ax.set_ylim(2000, 1650)\n",
    "    ax.set_title(nice_names[name])\n",
    "    # make top x limit and bottom x limit equal\n",
    "    xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    ax.set_xlim(-xlim, xlim)\n",
    "axs[0].set_ylabel('Year')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/historical.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get error on ratio calculations\n",
    "def clarke_ratio(A, a, B, b, C=100, c=0):\n",
    "    # if A:B is the ratio, we want x where A:B = C:x\n",
    "    value = (B / A) * C\n",
    "    uncertainty = np.sqrt((B*C*a/A)**2 + (C*b)**2 + (B*c)**2)/A\n",
    "    return value, uncertainty\n",
    "def clarke_quotient(A, a, B, b):\n",
    "    # get the ratio B:A and its error\n",
    "    value = B/A\n",
    "    uncertainity = np.sqrt((B*a/A)**2+b**2)/A\n",
    "    return value, uncertainity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_df = pd.read_csv('data/clarke/H-O-mass.csv', comment='#')\n",
    "ho_df['uncertainty'] = ho_df['proberr'] / 0.6745\n",
    "agcl_df = pd.read_csv('data/clarke/Ag-Cl-mass.csv', comment='#')\n",
    "agcl_df['uncertainty'] = agcl_df['proberr'] / 0.6745\n",
    "agi_df = pd.read_csv('data/clarke/Ag-I-mass.csv', comment='#')\n",
    "agi_df['uncertainty'] = agi_df['proberr'] / 0.6745\n",
    "agbr_df = pd.read_csv('data/clarke/Ag-Br-mass.csv', comment='#')\n",
    "agbr_df['uncertainty'] = agbr_df['proberr'] / 0.6745\n",
    "no_df = pd.read_csv('data/clarke/N-mass.csv', comment='#')\n",
    "no_df['uncertainty'] = no_df['proberr'] / 0.6745\n",
    "co_df = pd.read_csv('data/clarke/C-mass.csv', comment='#')\n",
    "co_df['uncertainty'] = co_df['proberr'] / 0.6745\n",
    "\n",
    "datasets['ho'] = ho_df\n",
    "datasets['agcl'] = agcl_df\n",
    "datasets['agi'] = agi_df\n",
    "datasets['agbr'] = agbr_df\n",
    "# datasets['no'] = no_df\n",
    "# datasets['co'] = co_df\n",
    "\n",
    "truths['agcl'] = clarke_ratio(107.8682, 0.0002, 35.453, 0.004, 100, 0)\n",
    "truths['agbr'] = clarke_ratio(107.8682, 0.0002, 79.904, 0.003, 100, 0)\n",
    "truths['agi'] = clarke_ratio(107.8682, 0.0002, 126.90447, 0.00003, 100, 0)\n",
    "truths['ho'] = clarke_quotient(1.0080, 0.0002, 15.9995, 0.0005)\n",
    "# truths['no'] = clarke_ratio(15.9995, 0.0005, 14.007, 0.001, 16, 0)\n",
    "# truths['co'] = clarke_ratio(15.9995, 0.0005, 12.011, 0.002, 16, 0)\n",
    "\n",
    "nice_names['ho'] = 'O:H mass ratio'\n",
    "nice_names['agcl'] = 'Ag:Cl mass ratio'\n",
    "nice_names['agi'] = 'Ag:I mass ratio'\n",
    "nice_names['agbr'] = 'Ag:Br mass ratio'\n",
    "# nice_names['no'] = 'N mass (O=16)'\n",
    "# nice_names['co'] = 'C mass (O=16)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 3))\n",
    "from methods import birge, random_effects_hksj, binomial_method\n",
    "\n",
    "plot_est = False\n",
    "chemistry_keys = ['ho', 'agcl', 'agi', 'agbr']\n",
    "\n",
    "for i, name in enumerate(chemistry_keys):\n",
    "    ax = axs.flatten()[i]\n",
    "    # values = np.array(datasets[name].value - truths[name])\n",
    "    truth = truths[name][0]\n",
    "    err = truths[name][1]\n",
    "    ax.axvspan(truth-err, truth+err, color='black', alpha=0.3)\n",
    "\n",
    "    values = np.array(datasets[name].value)\n",
    "    errs = np.array(datasets[name].uncertainty)\n",
    "    # sort by decreasing error\n",
    "    sort_idx = np.argsort(errs)[::-1]\n",
    "    values = values[sort_idx]\n",
    "    errs = errs[sort_idx]\n",
    "    \n",
    "    ax.errorbar(values, np.arange(len(values)), xerr=errs, fmt='.', markersize=2, linewidth=1, color='black')\n",
    "    ax.invert_yaxis()\n",
    "    # xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    # ax.set_xlim(-xlim, xlim)\n",
    "    if plot_est:\n",
    "        interval_birge, _, _, _ = birge(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_birge[0], color='red', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_birge[1], color='red', linestyle='--', linewidth=1)\n",
    "        interval_re, _, _, _ = random_effects_hksj(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_re[0], color='blue', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_re[1], color='blue', linestyle='--', linewidth=1)\n",
    "        binomial_lower, _ = binomial_method(values, p=0.5, target=0.15865, which='lower')\n",
    "        ax.axvline(binomial_lower, color='green', linestyle='--', linewidth=1)\n",
    "        binomial_upper, _ = binomial_method(values, p=0.5, target=0.15865, which='upper')\n",
    "        ax.axvline(binomial_upper, color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_title(nice_names[name])\n",
    "\n",
    "    # ax.axvline(truth, color='black', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth-err, color='grey', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth+err, color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # ax.set_xlabel(xlabels[name])\n",
    "    # remove y ticks\n",
    "    ax.set_yticks([])\n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    xmin = ax.get_xlim()[0]\n",
    "    xmax = ax.get_xlim()[1]\n",
    "    ax.set_xlim(min(xmin, truth-err), max(xmax, truth+err))\n",
    "    # add top ticks\n",
    "    ax.tick_params(axis='x', top=True)\n",
    "    # make ticks point inwards\n",
    "    ax.tick_params(direction='in')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/chemical.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "particle_keys = sorted([f.split('.')[0] for f in os.listdir('data/pdg1970') if f.endswith('.csv')])\n",
    "print(particle_keys)\n",
    "units = {}\n",
    "for p in particle_keys:\n",
    "    path = f'data/pdg1970/{p}.csv'\n",
    "    datasets[p] = pd.read_csv(path, comment='#')\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        nice_names[p] = lines[0].strip('# ').strip('\\n')\n",
    "        units[p] = lines[1].strip('# ').strip('\\n')\n",
    "        value = float(lines[2].split(':')[1].strip())\n",
    "        sigma = float(lines[3].split(':')[1].strip())\n",
    "        truths[p] = (value, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(particle_keys))\n",
    "fig, axs = plt.subplots(6, 3, figsize=(8, 8))\n",
    "from methods import birge, random_effects_hksj, binomial_method\n",
    "assert len(particle_keys) <= len(axs.flatten())\n",
    "plot_est = False\n",
    "# particle_keys = ['lambda-lifetime', 'sigma+-lifetime', 'pion-mass-diff', 'charged-kaon-lifetime', 'charged-pion-lifetime', 'eta-mass']\n",
    "\n",
    "for i, name in enumerate(particle_keys):\n",
    "    ax = axs.flatten()[i]\n",
    "    # values = np.array(datasets[name].value - truths[name])\n",
    "    truth = truths[name][0]\n",
    "    err = truths[name][1]\n",
    "    ax.axvspan(truth-err, truth+err, color='black', alpha=0.3)\n",
    "\n",
    "    values = np.array(datasets[name].value)\n",
    "    errs = np.array(datasets[name].uncertainty)\n",
    "    # sort by decreasing error\n",
    "    sort_idx = np.argsort(datasets[name].year)\n",
    "    values = values[sort_idx]\n",
    "    errs = errs[sort_idx]\n",
    "    \n",
    "    ax.errorbar(values, np.arange(len(values)), xerr=errs, fmt='.', markersize=2, linewidth=1, color='black')\n",
    "    ax.invert_yaxis()\n",
    "    # xlim = max(abs(ax.get_xlim()[0]), abs(ax.get_xlim()[1]))\n",
    "    # ax.set_xlim(-xlim, xlim)\n",
    "    if plot_est:\n",
    "        interval_birge, _, _, _ = birge(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_birge[0], color='red', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_birge[1], color='red', linestyle='--', linewidth=1)\n",
    "        interval_re, _, _, _ = random_effects_hksj(values, errs, coverage=0.6827)\n",
    "        ax.axvline(interval_re[0], color='blue', linestyle='--', linewidth=1)\n",
    "        ax.axvline(interval_re[1], color='blue', linestyle='--', linewidth=1)\n",
    "        binomial_lower, _ = binomial_method(values, p=0.5, target=0.15865, which='lower')\n",
    "        ax.axvline(binomial_lower, color='green', linestyle='--', linewidth=1)\n",
    "        binomial_upper, _ = binomial_method(values, p=0.5, target=0.15865, which='upper')\n",
    "        ax.axvline(binomial_upper, color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_title(f'{nice_names[name]} {units[name]}')\n",
    "\n",
    "    # ax.axvline(truth, color='black', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth-err, color='grey', linestyle='--', linewidth=1)\n",
    "    # ax.axvline(truth+err, color='grey', linestyle='--', linewidth=1)\n",
    "    \n",
    "    # ax.set_xlabel(xlabels[name])\n",
    "    # remove y ticks\n",
    "    ax.set_yticks([])\n",
    "    ax.get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    xmin = ax.get_xlim()[0]\n",
    "    xmax = ax.get_xlim()[1]\n",
    "    ax.set_xlim(min(xmin, truth-err), max(xmax, truth+err))\n",
    "    # add top ticks\n",
    "    ax.tick_params(axis='x', top=True)\n",
    "    # make ticks point inwards\n",
    "    ax.tick_params(direction='in')\n",
    "\n",
    "# remove unused axes\n",
    "for ax in axs.flatten()[len(particle_keys):]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/particles.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "from methods import sign_rank_test\n",
    "\n",
    "names = list(datasets.keys())\n",
    "\n",
    "results = {}\n",
    "\n",
    "def format_number(x):\n",
    "    if x == -np.inf:\n",
    "        return r'$\\approx-\\infty$'\n",
    "    if x == np.inf:\n",
    "        return r'$\\approx\\infty$'\n",
    "    if x >= 1e2 or x <= -1e2:\n",
    "        return f'${str(int(x))}$'\n",
    "    return r'$\\num{{{0:.2g}}}$'.format(x)\n",
    "\n",
    "def fmt_result(result):\n",
    "    # result is a list\n",
    "    minmax = [min(result), max(result)]\n",
    "    result_fmt = [format_number(x) for x in minmax]\n",
    "    # get unique values (preserving order)\n",
    "    result_fmt = pd.unique(np.array(result_fmt))\n",
    "    if len(result_fmt) == 1:\n",
    "        return result_fmt[0]\n",
    "    else:\n",
    "        return f'[{\", \".join(result_fmt)}]'\n",
    "\n",
    "for n in names:\n",
    "    results[n] = {}\n",
    "    results[n]['count'] = fmt_result([len(datasets[n])])\n",
    "\n",
    "    truth_vals = []\n",
    "    if hasattr(truths[n], '__iter__'):\n",
    "        truth_vals.append(truths[n][0]-truths[n][1])\n",
    "        truth_vals.append(truths[n][0]+truths[n][1])\n",
    "        truth_vals.append(truths[n][0])\n",
    "    else:\n",
    "        truth_vals.append(truths[n])\n",
    "    \n",
    "    results[n]['num_over'] = fmt_result([np.sum(datasets[n].value > t) for t in truth_vals])\n",
    "    results[n]['prop_over'] = fmt_result([np.sum(datasets[n].value > t) / len(datasets[n]) for t in truth_vals])\n",
    "\n",
    "    # binomial test\n",
    "    results[n]['binom_p_value'] = fmt_result([binomtest(np.sum(datasets[n].value > t), len(datasets[n]), p=0.5, alternative='two-sided').pvalue for t in truth_vals])\n",
    "\n",
    "    results[n]['sign_rank_p_value'] = fmt_result([sign_rank_test(datasets[n].value, t) for t in truth_vals])\n",
    "\n",
    "# put all the results in a pandas dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.index = [nice_names[n] for n in names]\n",
    "\n",
    "# use np to save latex table with & separator\n",
    "rows = results_df.values.tolist()\n",
    "rows = [list(row) for row in rows]\n",
    "rows = [[nice_names[n]] + rows[i] for i, n in enumerate(names)]\n",
    "txt = ' \\\\\\\\\\n'.join([' & '.join(row) for row in rows])\n",
    "print(txt)\n",
    "with open('tables/hist-sym.tex', 'w') as f:\n",
    "    f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import birge, random_effects_mle\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "results = {}\n",
    "def fmt_result(r, bold=False):\n",
    "    if bold:\n",
    "        start = r'$\\mathbf{'\n",
    "        end = r'}$'\n",
    "    else:\n",
    "        start = r'$'\n",
    "        end = r'$'\n",
    "    if r == -np.inf:\n",
    "        return r'$\\approx-\\infty$'\n",
    "    elif r < -100:\n",
    "        return start + str(int(r)) + end\n",
    "    else:\n",
    "        return start + r'{:.3g}'.format(r) + end\n",
    "category_map = {k: 'chemistry' for k in chemistry_keys}\n",
    "category_map.update({k: 'particle' for k in particle_keys})\n",
    "category_map.update({k: 'historical' for k in historical_keys})\n",
    "\n",
    "key_order = []\n",
    "\n",
    "for n in names:\n",
    "    values = datasets[n].value\n",
    "    sigmas = datasets[n].uncertainty\n",
    "    has_sigma = ~np.isnan(sigmas)\n",
    "    values = values[has_sigma]\n",
    "    sigmas = sigmas[has_sigma]\n",
    "    if len(values) < 2:\n",
    "        continue\n",
    "    key_order.append(n)\n",
    "    truth = truths[n][0] if hasattr(truths[n], '__iter__') else truths[n]\n",
    "    # scaler = truth\n",
    "    # values = values/scaler\n",
    "    # sigmas = sigmas/scaler\n",
    "    # truth = truth/scaler\n",
    "    results[n] = {}\n",
    "\n",
    "    _, muhat_birge, _, chat = birge(values, sigmas, coverage=0.6827, truth=truth)\n",
    "    # brs.append(chat)\n",
    "    # mean_sigma = np.mean(sigmas)\n",
    "    # muhat_re, _, tau = random_effects_dl_base(values, sigmas)\n",
    "    # taus.append(np.mean(tau/sigmas))\n",
    "    _, muhat_re, _, tau = random_effects_mle(values, sigmas, coverage=0.6827, truth=truth)\n",
    "    # taus.append(np.mean(tau/sigmas))\n",
    "    # I2s.append(I2(values, sigmas))\n",
    "\n",
    "    # # generate values with same sigmas but no unaccounted for errors.\n",
    "    # # to be used as a control when analyzing the distribution of chat and tau\n",
    "    # values_control = np.random.normal(loc=0, scale=sigmas)\n",
    "    # _, _, _, chat_cont = birge(values_control, sigmas, coverage=0.6827)\n",
    "    # brs_cont.append(chat_cont)\n",
    "    # _, _, _, tau_cont = random_effects_mle(values_control, sigmas, coverage=0.6827)\n",
    "    # taus_cont.append(np.mean(tau_cont/sigmas))\n",
    "    # I2s_cont.append(I2(values_control, sigmas))\n",
    "\n",
    "    # # errscale_ps.append(errscale_test(values, sigmas))\n",
    "    # # errscale_ps_cont.append(errscale_test(values_control, sigmas))\n",
    "\n",
    "    results[n]['name'] = nice_names[n]\n",
    "    results[n]['count'] = len(values)\n",
    "    # print(norm.pdf(values, loc=muhat_birge, scale=sigmas*chat))\n",
    "    results[n]['birge_loglike'] = np.sum(norm.logpdf(values, loc=muhat_birge, scale=sigmas*chat))\n",
    "    results[n]['re_loglike'] = np.sum(norm.logpdf(values, loc=muhat_re, scale=np.sqrt(sigmas**2+tau**2)))\n",
    "    results[n]['fe_loglike'] = np.sum(norm.logpdf(values, loc=muhat_birge, scale=sigmas))\n",
    "\n",
    "    category = category_map[n]\n",
    "    if category not in results:\n",
    "        # dict with default value of zero\n",
    "        results[category] = defaultdict(int)\n",
    "    results[category]['count'] += len(values)\n",
    "    for r in ['birge_loglike', 're_loglike', 'fe_loglike']:\n",
    "        results[category][r] += results[n][r]\n",
    "    if 'total' not in results:\n",
    "        results['total'] = defaultdict(int)\n",
    "    results['total']['count'] += len(values)\n",
    "    for r in ['birge_loglike', 're_loglike', 'fe_loglike']:\n",
    "        results['total'][r] += results[n][r]\n",
    "\n",
    "\n",
    "\n",
    "for res in results.values():\n",
    "    res['count'] = fmt_result(res['count'])\n",
    "\n",
    "    loglike_keys = ['birge_loglike', 're_loglike', 'fe_loglike']\n",
    "    loglike_values = [res[k] for k in loglike_keys]\n",
    "    largest_idx = np.argmax(loglike_values)\n",
    "    if len(np.unique(loglike_values)) == 1:\n",
    "        largest_idx = np.nan\n",
    "    for i, r in enumerate(loglike_keys):\n",
    "        res[r] = fmt_result(res[r], bold=(i==largest_idx))\n",
    "\n",
    "results['total']['name'] = 'Total'\n",
    "results['historical']['name'] = 'Total (historical)'\n",
    "results['chemistry']['name'] = 'Total (chemistry)'\n",
    "results['particle']['name'] = 'Total (particle)'\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "# results_df.index = [r['name'] for r in results.values()]\n",
    "# sort to be: chemistry, particle, total chemistry, total particle, total\n",
    "row_order = key_order + ['historical','chemistry', 'particle', 'total']\n",
    "results_df = results_df.loc[row_order]\n",
    "\n",
    "# use np to save latex table with & separator\n",
    "rows = results_df.values.tolist()\n",
    "hline_idxs = [2, 2+len(chemistry_keys), 2+len(chemistry_keys)+len(particle_keys), -4, -1]\n",
    "for i in hline_idxs:\n",
    "    rows[i][0] = r'\\hline ' + rows[i][0]\n",
    "txt = ' \\\\\\\\\\n'.join([' & '.join(row) for row in rows])\n",
    "print(txt)\n",
    "with open('tables/hist-syst.tex', 'w') as f:\n",
    "    f.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(datasets['agi'].value)\n",
    "sigma = np.array(datasets['agi'].uncertainty)\n",
    "\n",
    "import pymc as pm\n",
    "print(y)\n",
    "n = len(y)\n",
    "width = np.max(y) - np.min(y)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    theta = pm.Normal('theta', np.mean(y), np.mean(y))\n",
    "    # scaler_rate = pm.Exponential('scaler_rate', 0.2)\n",
    "    # scalers = pm.Exponential('scalers', scaler_rate, shape=n)+1\n",
    "    # y_pred = pm.Normal('y_pred', theta, sigma*scalers, observed=y)\n",
    "\n",
    "    # adder_rate = pm.Exponential('adder_rate', 10/width)\n",
    "    adders = pm.Exponential('adders', 5/width, shape=n)\n",
    "    y_pred = pm.Normal('y_pred', theta, np.sqrt(sigma**2+adders**2), observed=y)\n",
    "\n",
    "    trace = pm.sample(draws=1000, tune=1000, chains=4, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    plt.hist(trace.posterior['scalers'].values[:,:,i].flatten()+1, bins=100, histtype='step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.posterior['scalers'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trace.posterior['theta'].values.flatten(), bins=100)\n",
    "qs = np.quantile(trace.posterior['theta'].values.flatten(), [0.16, 0.84])\n",
    "plt.axvline(qs[0], color='red', linestyle='--', linewidth=1)\n",
    "plt.axvline(qs[1], color='red', linestyle='--', linewidth=1)\n",
    "ymax = plt.ylim()[1]\n",
    "if 'scalers' in trace.posterior:\n",
    "    scaler_qs = np.quantile(trace.posterior['scalers'].values, [0.25, 0.5, 0.75], axis=(0,1))+1\n",
    "    print(scaler_qs.shape)\n",
    "    for i in range(3):\n",
    "        plt.errorbar(y, np.linspace(ymax/len(y), ymax, len(y)), xerr=sigma*scaler_qs[i], fmt='.', markersize=2, linewidth=1, color='black', capsize=2)\n",
    "if 'adders' in trace.posterior:\n",
    "    adder_qs = np.quantile(trace.posterior['adders'].values, [0.25, 0.5, 0.75], axis=(0,1))\n",
    "    print(adder_qs.shape)\n",
    "    for i in range(3):\n",
    "        plt.errorbar(y, np.linspace(ymax/len(y), ymax, len(y)), xerr=sigma+adder_qs[i], fmt='.', markersize=2, linewidth=1, color='black', capsize=2)\n",
    "# sigmas_adjust = sigma * np.median(trace.posterior['scalers'].values, axis=(0,1))\n",
    "\n",
    "plt.errorbar(y, np.linspace(ymax/len(y), ymax, len(y)), xerr=sigma, fmt='.', markersize=2, linewidth=2, color='black')\n",
    "\n",
    "# plt.ylim(0, ymax)\n",
    "# plt.xlim(qs[0], qs[1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
