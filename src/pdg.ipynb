{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = pdg.connect(\"sqlite:///data/pdgall-2024-v0.1.4.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = []\n",
    "uncertainties = []\n",
    "for edition in api.editions:\n",
    "    api.edition = edition\n",
    "    particle = api.get_particle_by_name(\"t\")\n",
    "    print(particle.pdgid)\n",
    "    mass = particle.mass\n",
    "    if mass is None:\n",
    "        print(particle.has_mass_entry)\n",
    "        print([m.summary_values() for m in particle.masses()])\n",
    "        break\n",
    "    masses.append(particle.mass)\n",
    "    uncertainties.append(particle.mass_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "masses = np.array(masses)\n",
    "uncertainties = np.array(uncertainties)\n",
    "editions = np.array(api.editions).astype(int)[: len(masses)]\n",
    "plt.plot(editions, masses, color=\"black\")\n",
    "plt.fill_between(\n",
    "    editions, masses - uncertainties, masses + uncertainties, color=\"gray\", alpha=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.edition = \"2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_particle_by_name(\"t\").mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([m.summary_values() for m in api.get_particle_by_name(\"t\").masses()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = pd.read_html(\n",
    "    \"https://pdglive.lbl.gov/DataBlock.action?node=Q007TP\", encoding=\"ISO-8859-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[2].copy()\n",
    "df = df[~pd.isna(df[\"DOCUMENT ID\"]) & pd.isna(df[\"Unnamed: 6\"])]\n",
    "# drop all unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "# drop rows containing 'DOCUMENT ID'\n",
    "df = df[~df[\"DOCUMENT ID\"].str.contains(\"DOCUMENT ID\")]\n",
    "df = df[~df[\"DOCUMENT ID\"].str.contains(\"References\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "superseded = {\n",
    "    \"SIRUNYAN 2018DE\": \"TUMASYAN 2023BB\",\n",
    "    \"SIRUNYAN 2017L\": \"TUMASYAN 2021G\",\n",
    "    \"AALTONEN 2007B\": \"AALTONEN 2011AK\",\n",
    "    \"AALTONEN 2011AK\": \"AALTONEN 2013H\",\n",
    "    \"ABAZOV 2011R\": \"ABAZOV 2012AB\",\n",
    "    \"CHATRCHYAN 2011F\": \"CHATRCHYAN 2012BA\",\n",
    "    \"AALTONEN 2010E\": \"AALTONEN 2012G\",\n",
    "    \"AALTONEN 2007D\": \"AALTONEN 2012G\",\n",
    "    \"ABAZOV 2006U\": \"ABAZOV 2008AH\",\n",
    "}\n",
    "current = [\n",
    "    \"AAD 2023N\",\n",
    "    \"TUMASYAN 2023BB\",\n",
    "    \"TUMASYAN 2023Z\",\n",
    "    \"TUMASYAN 2021G\",\n",
    "    \"SIRUNYAN 2020AR\",\n",
    "    \"AABOUD 2019AC\",\n",
    "    \"SIRUNYAN 2019AP\",\n",
    "    \"SIRUNYAN 2019AR\",\n",
    "    \"KHACHATRYAN 2016AK\",\n",
    "    \"TEVEWWG 2016\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import binomial_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def parse_measurement(s):\n",
    "    \"\"\"\n",
    "    Parse a measurement string of the form:\n",
    "      $value$ [ $±stat$ ] [ ${}^{+stat+}_{-stat-}$ ] [ $±syst$ ] [ ${}^{+syst+}_{-syst-}$ ]\n",
    "    into a dict with keys:\n",
    "      'value', 'stat-', 'stat+', 'syst-', 'syst+', 'err-', 'err+'\n",
    "    \"\"\"\n",
    "    # 1) pull out all the $...$ groups\n",
    "    groups = re.findall(r\"\\$([^$]+)\\$\", s)\n",
    "    if not groups:\n",
    "        raise ValueError(\"No $...$ groups found\")\n",
    "    # first group is the central value\n",
    "    value = float(groups[0].strip())\n",
    "    err_groups = groups[1:]  # the rest are error specs\n",
    "\n",
    "    # helper to parse one error group (symmetric or asymmetric) -> (neg, pos)\n",
    "    def _parse_err(g):\n",
    "        g = g.strip()\n",
    "        # symmetric: ± or \\pm\n",
    "        m = re.search(r\"[±\\\\]pm\\s*([0-9]*\\.?[0-9]+)\", g)\n",
    "        if m:\n",
    "            v = float(m.group(1))\n",
    "            return v, v\n",
    "        # asymmetric: look for +num and -num\n",
    "        m_plus = re.search(r\"\\+\\s*([0-9]*\\.?[0-9]+)\", g)\n",
    "        m_minus = re.search(r\"-\\s*([0-9]*\\.?[0-9]+)\", g)\n",
    "        if m_plus and m_minus:\n",
    "            return float(m_minus.group(1)), float(m_plus.group(1))\n",
    "        raise ValueError(f\"Could not parse error group: {g}\")\n",
    "\n",
    "    # initialize result\n",
    "    res = {\n",
    "        \"value\": value,\n",
    "        \"stat-\": None,\n",
    "        \"stat+\": None,\n",
    "        \"syst-\": None,\n",
    "        \"syst+\": None,\n",
    "        \"err-\": None,\n",
    "        \"err+\": None,\n",
    "    }\n",
    "\n",
    "    if len(err_groups) == 1:\n",
    "        # single error → total error\n",
    "        neg, pos = _parse_err(err_groups[0])\n",
    "        res[\"err-\"], res[\"err+\"] = neg, pos\n",
    "    elif len(err_groups) == 2:\n",
    "        # two errors → stat then syst\n",
    "        stat_neg, stat_pos = _parse_err(err_groups[0])\n",
    "        syst_neg, syst_pos = _parse_err(err_groups[1])\n",
    "        res[\"stat-\"], res[\"stat+\"] = stat_neg, stat_pos\n",
    "        res[\"syst-\"], res[\"syst+\"] = syst_neg, syst_pos\n",
    "        res[\"err-\"] = np.sqrt(res[\"stat-\"] ** 2 + res[\"syst-\"] ** 2)\n",
    "        res[\"err+\"] = np.sqrt(res[\"stat+\"] ** 2 + res[\"syst+\"] ** 2)\n",
    "    elif len(err_groups) == 0:\n",
    "        # no errors at all\n",
    "        pass\n",
    "    else:\n",
    "        # you could expand this to handle three or more error groups,\n",
    "        # but based on your description you only need 1 or 2\n",
    "        raise ValueError(f\"Unexpected number of error groups: {len(err_groups)}\")\n",
    "    res[\"symerr\"] = (res[\"err-\"] + res[\"err+\"]) / 2\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# --- examples ---\n",
    "tests = [\n",
    "    \"$174.41$ $\\\\pm0.39$ $\\\\pm0.71$\",\n",
    "    \"$171.77$ $\\\\pm0.37$\",\n",
    "    \"$172.13$ ${}^{+0.76}_{-0.77}$\",\n",
    "    \"$199$ ${}^{+19}_{-21}$ $\\\\pm22$\",\n",
    "    \"$174$ $\\\\pm10$ ${}^{+13}_{-12}$\",\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(t, \"→\", parse_measurement(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(s):\n",
    "    match = re.search(r\"\\b(19|20)\\d{2}\", s)\n",
    "    if match:\n",
    "        return int(int(match.group()))\n",
    "    else:\n",
    "        raise ValueError(f\"No year found in string: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply parse_measurement to the 'VALUE (GeV)' column of the dataframe\n",
    "parsed = list(df[\"VALUE (GeV)\"].apply(parse_measurement))\n",
    "# add these to dataframe as new columns\n",
    "for key in parsed[0].keys():\n",
    "    df[key] = [p[key] for p in parsed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2024 = df[df[\"DOCUMENT ID\"].str.contains(\"|\".join(current))]\n",
    "# take only the first row for each document\n",
    "df_2024 = df_2024.drop_duplicates(subset=[\"DOCUMENT ID\"], keep=\"first\")\n",
    "df_2024\n",
    "values = np.array(df_2024[\"value\"])\n",
    "uncertainties = np.array(df_2024[\"symerr\"])\n",
    "from methods import binomial_method, random_effects_hksj, birge\n",
    "\n",
    "l, prob = binomial_method(np.sort(values), 0.5, which=\"lower\")\n",
    "u, prob = binomial_method(np.sort(values), 0.5, which=\"upper\")\n",
    "print(l, u)\n",
    "print(1 - 2 * prob)\n",
    "interval, _, _, _ = random_effects_hksj(values, uncertainties, coverage=0.6827)\n",
    "print(interval)\n",
    "interval, _, _, c = birge(values, uncertainties, coverage=0.6827, pdg=True)\n",
    "print(interval, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array(list(df[\"DOCUMENT ID\"].apply(get_year)))\n",
    "# add jitter\n",
    "jitter = np.random.normal(0, 0.5, len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([p[\"value\"] for p in parsed])\n",
    "errors = np.array([p[\"symerr\"] for p in parsed])\n",
    "n = len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(\n",
    "    values,\n",
    "    years + jitter,\n",
    "    xerr=errors,\n",
    "    fmt=\"o\",\n",
    "    color=\"black\",\n",
    "    capsize=3,\n",
    "    linewidth=0.5,\n",
    "    markersize=2,\n",
    ")\n",
    "plt.fill_betweenx(\n",
    "    editions, masses - uncertainties, masses + uncertainties, color=\"red\", alpha=0.5\n",
    ")\n",
    "# change y axis to df['DOCUMENT ID']\n",
    "# plt.yticks(range(n), df['DOCUMENT ID'])\n",
    "# invert y axis\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1 / errors\n",
    "wm = np.sum(w * values) / np.sum(w)\n",
    "resids = values - wm\n",
    "resids_norm = resids / errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## qq plot\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "theoretical, actual = stats.probplot(resids_norm, dist=\"norm\", fit=False)\n",
    "errors_sort = np.array([errors[i] for i in np.argsort(resids_norm)])\n",
    "plt.scatter(theoretical, actual, c=np.log(errors_sort))\n",
    "# set aspect equal\n",
    "plt.xlim([-3, 3])\n",
    "plt.ylim([-3, 3])\n",
    "\n",
    "# plot x=y\n",
    "plt.plot(theoretical, theoretical, \"r--\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate kurtosis\n",
    "kurtosis = stats.kurtosis(resids_norm)\n",
    "kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(resids_norm[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "normaltest(resids_norm[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
